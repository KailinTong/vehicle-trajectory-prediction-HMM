{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------隐马尔可夫模型解决北京市车辆交通预测问题------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 声明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 由于使用经纬度表示和计算并不方便，本分析中一律采用m为单位，如需转换为经纬度，请使用我提供的转换函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思路：<br>\n",
    "<br>\n",
    "隐藏的状态：车的速度、方向等因素（但这是连续值，是否需要思考如何转为‘堵车’‘畅通’等离散值）<br>\n",
    "可见的观测：车的位置、位移（距上次测量的位移）<br>\n",
    "<br>\n",
    "A矩阵：状态转移矩阵，指车的状态切换矩阵，如从堵车状态转移为畅通状态<br>\n",
    "B矩阵：发射（观测）矩阵，指状态显现出的形式，这里采用高斯分布<br>\n",
    "    <br>\n",
    "大体算法：<br>\n",
    "1、求出每个点的速度、方向、速度较上一点的改变量、方向较上一点的改变量、原地停留时间(v,theta,u,diata,stops_time)<br>\n",
    "2、用维特比算法对(x,y,v,theta,u,diata)进行隐马尔可夫模型训练<br>\n",
    "3、通过后向算法进行预测<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预处理中出现了问题，tdf和ctdf的stops_time有误，需修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train_set...\n",
      "transforming lon and lat to x and y...\n",
      "computing v and u...\n",
      "computing stops_time and restart\n",
      "fixing the error number...\n",
      "df has been output\n",
      "cdf has been ouput\n",
      "loading test_set...\n",
      "transforming lon and lat to x and y...\n",
      "computing v and u...\n",
      "computing stops_time and restart\n",
      "fixing the error number...\n",
      "tdf has been output\n",
      "ctdf has been ouput\n",
      "data_pretreatment has been done\n",
      "all variables have been removed\n"
     ]
    }
   ],
   "source": [
    "%run data_pretreatment.py\n",
    "%reset -f\n",
    "print 'all variables have been removed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预备库环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series,DataFrame\n",
    "import seaborn as sns\n",
    "from pprint import pprint as pp\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "from hmmlearn import hmm\n",
    "import math\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run funcs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回顾上次实验的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于用训练集中前500个数据作为训练集，训练集中后1500个数据作为测试集的模型\n",
    "\n",
    "取上一点的state直接当做下一点的state的结果是：16.689852160660948<br>\n",
    "取proba最大值的state作为state的结果是：16.463392959141991<br>\n",
    "取v均值作为v的结果是：14.644368553942261<br>\n",
    "<br>\n",
    "\n",
    "使用所有源训练集的数据作为训练集,使用所有源训练集的数据作为测试集的结果：<br>\n",
    "分成8个状态的结果<br>\n",
    "取proba最大值的state作为state的结果是：14.2193538343857  (疑有误，可能为取v期望作为v的结果)<br>\n",
    "分成16个状态的结果<br>\n",
    "取v期望的结果是：16.418680700780275<br>\n",
    "\n",
    "\n",
    "model      | model1      | model2 |model3|model4|model5\n",
    "------------ | ------------- | ------------ | ------------ \n",
    "discribe    |  取上一点的state直接当做下一点的state | 取proba最大值的state作为state|取v的期望|取proba最大值的state作为state的结果|取v的期望\n",
    "component   | 8|8|8 |8|16\n",
    "item       | ||||200\n",
    "n_item     | 100|100|100|100|200\n",
    "trainset    | df[:500]  |  df[:500] | df[:500] |df|df\n",
    "testset    | df[500:] | df[500:] |df[500:] |tdf|tdf\n",
    "err_distance | 16.689852160660948  | 16.463392959141991 | 14.644368553942261|14.2193538343857|16.418680700780275\n",
    "\n",
    "\n",
    "\n",
    "分得更细，反倒效果变差了<br>\n",
    "<br>\n",
    "Interesting！<br>\n",
    "由于本例中存在很多v为0的点，当采用期望后这些v都被预测为4.5<br>\n",
    "所以我认为去v期望作为v的结果会很差，但是事实却相反<br>\n",
    "这可能说明：<br>\n",
    "* 第二种方法的极大误差值严重影响了错误率\n",
    "* 对于观测值为连续值的问题，用连续的期望代替离散值有天然的优越性\n",
    "* 将第二种方法和第三种方法结合可能会有更好的效果\n",
    "* 本方法还有很大的提升空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在demo跑出来了，下一步要优化<br>\n",
    "优化想法：<br>\n",
    "* 加入其它特征进行训练\n",
    "* 将训练集训练出的模型和测试集中将要预测的轨迹的点（除去要预测的点）训练出的小模型融合，这样的效果可能会更贴切该车的行车规律，结果可能更好\n",
    "* 调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从middata中加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../middata/df3.csv',index_col=0)   # index_col=0 可以去掉Unnamed0\n",
    "cdf = pd.read_csv('../middata/cdf1.csv',index_col=0)\n",
    "tdf = pd.read_csv('../middata/tdf4.csv',index_col=0)\n",
    "ctdf = pd.read_csv('../middata/ctdf2.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'fff' (DataFrame)\n",
      "Stored 'ttt' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# 生成用于测试代码的测试数据\n",
    "# 测试训练集\n",
    "fff = cdf[cdf['id']<20]\n",
    "# 测试测试集\n",
    "ttt = ctdf[ctdf['id']<20]\n",
    "# 并储存\n",
    "%store fff\n",
    "%store ttt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从models中加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在刚开始的时候没有注意保存的模型命名的问题，尤其是模型对应的traincol。\n",
    "\n",
    "以下是整理后的各模型参数：\n",
    "\n",
    "model                                 |trainset| traincol    |n_components | n_iter          |create_time\n",
    "-----------------------------------------------------|-------|--|----------|----------|------------------------------------------\n",
    "model_2000_car_300_iter_v_u_diata_12m2d21h31min.pkl  | cdf     |v u diata    |16        | 300           |12m2d21h31min\n",
    "model_test_v_u_diata_stops_12m2d19h48min.pkl       |cdf[:100*1600]|v u diata |12        | 50            |12m2d19h48min\n",
    "model_2000_car_200_iter_12m1d7h47min.pkl         | cdf     |v         |16        | 200           |12m1d7h47min\n",
    "model_2000_car_100_iter_v.pkl                   | cdf     |v         |8         |100           |-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2000_car_100_iter_v = joblib.load('../models/model_2000_car_100_iter_v.pkl')\n",
    "model_2000_car_200_iter_12m1d7h47min = joblib.load('../models/model_2000_car_200_iter_12m1d7h47min.pkl')\n",
    "model_test_v_u_diata_stops_12m2d19h48min = joblib.load('../models/model_test_v_u_diata_stops_12m2d19h48min.pkl')\n",
    "model_2000_car_300_iter_v_u_diata_12m2d21h31min = joblib.load('../models/model_2000_car_300_iter_v_u_diata_12m2d21h31min.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表中1,2模型类型相同，3,4模型类型相同<br>\n",
    "实验表明，其中1,3模型较2,4模型更好<br>\n",
    "故这里只选取1,3模型进行展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多特征训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了加入其它特征进入训练，我同时考虑了速度、加速度、方向改变量、原地停顿时间四个因素,但是结果很不理想，误差很大<br>\n",
    "没有演示实验，因为用于测试的模型比较粗糙，没有保留<br>\n",
    "精度比较高的模型还正在训练(已经训练一两天了，不知道还要训练多久)<br>\n",
    "于是我同时考虑了速度、加速度、方向改变量三个因素,但是误差还是很大<br>\n",
    "如下测试所见"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------*观察报告*---------\n",
      "每种状态对应的轨迹数\n",
      "状态 0 有 16345775 条轨迹\n",
      "状态 1 有 282462 条轨迹\n",
      "状态 2 有 374982 条轨迹\n",
      "状态 3 有 116518 条轨迹\n",
      "状态 4 有 156263 条轨迹\n",
      "状态 5 有 255575 条轨迹\n",
      "状态 6 有 42723 条轨迹\n",
      "状态 7 有 547820 条轨迹\n",
      "状态 8 有 782806 条轨迹\n",
      "状态 9 有 255734 条轨迹\n",
      "状态 10 有 362202 条轨迹\n",
      "状态 11 有 534367 条轨迹\n",
      "状态 12 有 170095 条轨迹\n",
      "状态 13 有 237555 条轨迹\n",
      "状态 14 有 387425 条轨迹\n",
      "状态 15 有 147698 条轨迹\n",
      "每种状态对应的观测\n",
      "每条轨迹长度: 2100\n",
      "轨迹数: 10000\n",
      "观测状态矩阵\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  5.42297393e+01   4.98010739e+01  -2.43646686e+00   0.00000000e+00]\n",
      " [  6.23644912e+01   1.78507821e+01   9.24222568e+01   0.00000000e+00]\n",
      " [  2.75682832e+01   3.24730373e+02   4.19715592e+00   0.00000000e+00]\n",
      " [  3.43089099e+01   1.53915221e+01   9.42156487e-12   0.00000000e+00]\n",
      " [  9.77850836e+01   8.42988064e+01   9.70866390e-01   0.00000000e+00]\n",
      " [  8.44573181e+02   7.60760568e+02  -2.40655108e+00   0.00000000e+00]\n",
      " [  2.69784094e+01   1.92395809e+01   9.01738316e+01   0.00000000e+00]\n",
      " [  0.00000000e+00   4.42073448e+01  -1.25877365e+01   0.00000000e+00]\n",
      " [  1.97213295e+02   1.47391321e+02  -1.18172042e+00   0.00000000e+00]\n",
      " [  6.25061415e+01   1.78104130e+01  -9.62020602e+01   0.00000000e+00]\n",
      " [  2.65166027e+01   1.90143446e+01  -9.94183738e+01   0.00000000e+00]\n",
      " [  1.82402951e+02   3.14585638e+01  -1.92955602e+00   0.00000000e+00]\n",
      " [  4.23464567e+02   2.49680064e+02  -2.67359736e+00   0.00000000e+00]\n",
      " [  1.06220309e+02   2.14213863e+01  -1.41643215e+00   0.00000000e+00]\n",
      " [  2.08228101e+01   6.61308508e+01  -2.16803220e+00   0.00000000e+00]]\n",
      "观察前5个下一点的观测值\n",
      "[[  3.63468294e+00   2.74199921e+00  -6.85696268e-02   0.00000000e+00]\n",
      " [  6.09003335e+02   5.93136284e+02  -2.16803058e+00   0.00000000e+00]\n",
      " [  3.63468294e+00   2.74199921e+00  -6.85696268e-02   0.00000000e+00]\n",
      " [  3.63468294e+00   2.74199921e+00  -6.85696268e-02   0.00000000e+00]\n",
      " [  3.63468294e+00   2.74199921e+00  -6.85696268e-02   0.00000000e+00]]\n",
      "取前5个预测点观察\n",
      "[[  37860.8960655    97805.25928   ]\n",
      " [  30318.07416337  100699.57635795]\n",
      " [  30077.50258019  102842.16271847]\n",
      " [  39533.85536633  108958.87774061]\n",
      " [  32976.05488018  101177.27371847]]\n",
      "欧氏距离误差均值 91.3441164368\n",
      "欧氏距离误差标准差 249.8545759\n"
     ]
    }
   ],
   "source": [
    "prediction(model_2000_car_300_iter_v_u_diata_12m2d21h31min,cdf,ctdf,traincol_name=['v','u','diata'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加速度和其角度diata必须同时考虑，不能拆开<br>\n",
    "所以我只好只考虑速度v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------*观察报告*---------\n",
      "每种状态对应的轨迹数\n",
      "状态 0 有 17157462 条轨迹\n",
      "状态 1 有 480867 条轨迹\n",
      "状态 2 有 266683 条轨迹\n",
      "状态 3 有 616035 条轨迹\n",
      "状态 4 有 52 条轨迹\n",
      "状态 5 有 247124 条轨迹\n",
      "状态 6 有 16251 条轨迹\n",
      "状态 7 有 0 条轨迹\n",
      "状态 8 有 218691 条轨迹\n",
      "状态 9 有 571654 条轨迹\n",
      "状态 10 有 103610 条轨迹\n",
      "状态 11 有 94408 条轨迹\n",
      "状态 12 有 212014 条轨迹\n",
      "状态 13 有 264689 条轨迹\n",
      "状态 14 有 750319 条轨迹\n",
      "状态 15 有 141 条轨迹\n",
      "每种状态对应的观测\n",
      "每条轨迹长度: 2100\n",
      "轨迹数: 10000\n",
      "观测状态矩阵\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  6.10505636e+01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  3.09428371e+02   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  4.38698485e+01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.17854605e+03   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.56911230e+02   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.19635438e+03   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  3.00105223e+04   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  8.94227970e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  6.78816256e+01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  2.28107678e+02   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  5.86620949e+02   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.22091989e+02   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.52211388e+01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  2.25879643e+01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  6.83653724e+03   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "观察前5个下一点的观测值\n",
      "[[  4.40020922   0.           0.           0.        ]\n",
      " [ 12.63068716   0.           0.           0.        ]\n",
      " [  4.4002095    0.           0.           0.        ]\n",
      " [  4.40020929   0.           0.           0.        ]\n",
      " [  4.40020929   0.           0.           0.        ]]\n",
      "取前5个预测点观察\n",
      "[[  37857.45653994   97805.57797356]\n",
      " [  30266.57877895  100972.50482618]\n",
      " [  30075.5261095   102842.166     ]\n",
      " [  39531.01247698  108958.12217342]\n",
      " [  32974.07840929  101177.277     ]]\n",
      "欧氏距离误差均值 16.5484281699\n",
      "欧氏距离误差标准差 55.6658401849\n"
     ]
    }
   ],
   "source": [
    "prediction(model_2000_car_200_iter_12m1d7h47min,cdf,ctdf,traincol_name=['v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果在预期范围内"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于使用模型融合的方法计算量较大，所以这里仅取部分数据进行检测<br>\n",
    "我正在跑检测所有测试集的程序，可能明天会跑出全部测试集的训练效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------*观察报告*---------\n",
      "每种状态对应的轨迹数\n",
      "状态 0 有 60184 条轨迹\n",
      "状态 1 有 2374 条轨迹\n",
      "状态 2 有 1126 条轨迹\n",
      "状态 3 有 3457 条轨迹\n",
      "状态 4 有 0 条轨迹\n",
      "状态 5 有 1179 条轨迹\n",
      "状态 6 有 59 条轨迹\n",
      "状态 7 有 0 条轨迹\n",
      "状态 8 有 1059 条轨迹\n",
      "状态 9 有 3000 条轨迹\n",
      "状态 10 有 480 条轨迹\n",
      "状态 11 有 389 条轨迹\n",
      "状态 12 有 1308 条轨迹\n",
      "状态 13 有 1282 条轨迹\n",
      "状态 14 有 4102 条轨迹\n",
      "状态 15 有 1 条轨迹\n",
      "每种状态对应的观测\n",
      "每条轨迹长度: 1600\n",
      "轨迹数: 50\n",
      "观测状态矩阵\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  6.10505636e+01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  3.09428371e+02   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  4.38698485e+01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.17854605e+03   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.56911230e+02   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.19635438e+03   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  3.00105223e+04   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  8.94227970e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  6.78816256e+01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  2.28107678e+02   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  5.86620949e+02   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.22091989e+02   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.52211388e+01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  2.25879643e+01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  6.83653724e+03   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "观察前5个下一点的观测值\n",
      "[[  4.40020922   0.           0.           0.        ]\n",
      " [  4.40020929   0.           0.           0.        ]\n",
      " [  4.40020929   0.           0.           0.        ]\n",
      " [  4.40021156   0.           0.           0.        ]\n",
      " [ 58.27171552   0.           0.           0.        ]]\n",
      "取前5个预测点观察\n",
      "[[  39838.9680598    96108.94038406]\n",
      " [  32006.88354865   97903.26344778]\n",
      " [  40122.86333947  101157.31343403]\n",
      " [  34579.55375253  110029.17385442]\n",
      " [  28341.36920168   98261.10777759]]\n",
      "欧氏距离误差均值 10.2927526198\n",
      "欧氏距离误差标准差 12.0008115976\n",
      "0 49\n",
      "[[ 14.79947231   0.           0.           0.        ]\n",
      " [  4.97972955   0.           0.           0.        ]\n",
      " [  4.35975642   0.           0.           0.        ]\n",
      " [  4.38021481   0.           0.           0.        ]\n",
      " [ 57.90150281   0.           0.           0.        ]\n",
      " [  4.34693211   0.           0.           0.        ]\n",
      " [  2.57724003   0.           0.           0.        ]\n",
      " [  3.97362861   0.           0.           0.        ]\n",
      " [  8.99017668   0.           0.           0.        ]\n",
      " [  1.92083256   0.           0.           0.        ]\n",
      " [  5.79141169   0.           0.           0.        ]\n",
      " [ 12.76641534   0.           0.           0.        ]\n",
      " [  4.83117534   0.           0.           0.        ]\n",
      " [ 14.5840303    0.           0.           0.        ]\n",
      " [  5.3339463    0.           0.           0.        ]\n",
      " [  4.54232531   0.           0.           0.        ]\n",
      " [ 12.72706778   0.           0.           0.        ]\n",
      " [  3.91625742   0.           0.           0.        ]\n",
      " [ 10.94067752   0.           0.           0.        ]\n",
      " [ 17.20365084   0.           0.           0.        ]\n",
      " [ 11.67876238   0.           0.           0.        ]\n",
      " [  7.11734004   0.           0.           0.        ]\n",
      " [ 14.63709656   0.           0.           0.        ]\n",
      " [  7.61843592   0.           0.           0.        ]\n",
      " [ 17.52746295   0.           0.           0.        ]\n",
      " [  3.38188599   0.           0.           0.        ]\n",
      " [  6.13705101   0.           0.           0.        ]\n",
      " [  7.92315488   0.           0.           0.        ]\n",
      " [  4.28762868   0.           0.           0.        ]\n",
      " [ 21.54789264   0.           0.           0.        ]\n",
      " [  5.79429758   0.           0.           0.        ]\n",
      " [  4.14270602   0.           0.           0.        ]\n",
      " [  2.97480949   0.           0.           0.        ]\n",
      " [  9.01184194   0.           0.           0.        ]\n",
      " [  6.32745344   0.           0.           0.        ]\n",
      " [  9.4272894    0.           0.           0.        ]\n",
      " [  5.65325134   0.           0.           0.        ]\n",
      " [  7.60612945   0.           0.           0.        ]\n",
      " [  5.592135     0.           0.           0.        ]\n",
      " [  3.54897674   0.           0.           0.        ]\n",
      " [  6.303577     0.           0.           0.        ]\n",
      " [ 21.55118767   0.           0.           0.        ]\n",
      " [  3.59908619   0.           0.           0.        ]\n",
      " [  9.61873927   0.           0.           0.        ]\n",
      " [  0.36524824   0.           0.           0.        ]\n",
      " [  9.57020077   0.           0.           0.        ]\n",
      " [  4.97145357   0.           0.           0.        ]\n",
      " [  1.43737752   0.           0.           0.        ]\n",
      " [  8.03342781   0.           0.           0.        ]\n",
      " [  6.98914603   0.           0.           0.        ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-719aa9e16874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mself_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2000_car_200_iter_12m1d7h47min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraincol_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_predict_base_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/liheyuan/Jupyter/hmm2/scripts/funcs.py\u001b[0m in \u001b[0;36mself_prediction\u001b[0;34m(model, train_df, test_df, traincol_name, base_point, anwser_point, self_n_components, self_n_iter, weight_predict_base_all)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mpredict_next_obs_base_self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mpredict_next_points_obs_base_all_and_self\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                 \u001b[0mweight_predict_base_all\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpredict_next_points_obs_base_all\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweight_predict_base_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpredict_next_obs_base_self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'全模型和自模型融合'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "self_prediction(model_2000_car_200_iter_12m1d7h47min,cdf,cdf[cdf['id']<50],traincol_name=['v'],weight_predict_base_all=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很不幸，报错了，因为main.ipynb文件是用来展示用的，我的探索、尝试部分是分散在其他几个文件之间的，<br>\n",
    "这可能导致main.ipynb文件的变量环境和其他文件的环境稍有区别,或其他问题<br>\n",
    "若要看到这里的数据，请移步fit.ipynb文件的第302块代码<br>\n",
    "这部分的数据显示，融合后的结果和融合前的结果相近，但错误率稍高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有好几个参数可调，但是调参太花费时间了，我这里只展示调高weight_predict_base_all后的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_prediction(model_2000_car_200_iter_12m1d7h47min,cdf,cdf[cdf['id']<50],traincol_name=['v'],weight_predict_base_all=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然上面的代码会报错，这里的代码就不尝试了<br>\n",
    "结果是稍好于weight_predict_base_all=0.5的测试结果，但还不如融合前的结果<br>\n",
    "这说明融合的效果确实不如不融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过以上实验，我有如下两个较大的疑问：<br>\n",
    "* 为什么多特征训练后的结果没有单一特征v训练出的结果好？我仔细检查过代码了，应该不是代码错误导致的误差\n",
    "* 为什么模型融合后的结果没有融合前的结果好？\n",
    "<br>\n",
    "\n",
    "这是我的猜想：<br>\n",
    "\n",
    "* 各个特征的重要程度是不同的，而将不太重要的特征如stops_time和很重要的特征v一同训练，反倒形成了干扰。比如通过查看源码，可知仅在聚类操作这一环节就会形成很大的干扰。同时特征多的话，特征之间的组合就更多，也就理应需要设置更多的隐含状态个数。但是由于计算量方面的考虑，我并没有增加隐含状态的个数，导致隐含状态的分类过于粗放，产生了巨大的误差。\n",
    "* 单个车辆的历史记录太少，如上次实验(见hmm文件夹)推断，这应该是一天中一段时间的轨迹数据。这样的数据规律性不强，反倒对原模型造成干扰。如果有数天的该车辆的行车数据，可能就能习得该车辆的行车习惯，这时进行模型融合可能会有更好的效果\n",
    "\n",
    "解决方案：<br>\n",
    "\n",
    "* 对各个特征分别建立隐马尔可夫模型，预测的时候取各个模型预测的参数，再使用这些参数算得预测结果。或想办法将数据加权之后再建立隐马尔可夫模型，但是这涉及调参的问题\n",
    "* 对该问题而言，只能放弃这种方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下一步工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自己写出hmm的各种算法，替换使用的hmmlearn库<br>\n",
    "我一直在找相关的代码，但教程、博客上的代码往往很简单或语焉不详，<br>\n",
    "不过即便这样，也应该是可以一步一步写的。<br>\n",
    "但主要问题是，这里的观测量是连续的，不是离散的，而关于建立观测量为连续量的隐马尔可夫模型的文章几乎没有，更不用说有代码示例的相关文章了<br>\n",
    "包括李航博士的《统计学习方法》上也没有讲如何建立观测量为连续量的隐马尔可夫模型<br>\n",
    "所以万般无奈下，我这几天在研究hmmlearn库的源码，但这对我有一定的难度，估计还要不少时间才能自己写出这些代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我用了两天用训练集的v特征训练出了一个迭代500次的模型，按理说效果应该是所有模型中最优的。但在我打开页面的时候，浏览器加载不下来，电脑几近卡死，导致我的Python核心崩溃，最终没有得到这个模型。<br>\n",
    "现在我还有一个多特征的较高精度模型正在训练，但我估计这个模型的效果不会很好<br>\n",
    "<br>\n",
    "这是我第一次处理这么大的数据，也是第一次使用部署在服务器上的jupyter，出现了很多意料之外的问题，花掉了许多时间，但熟悉之后，就没什么问题了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
